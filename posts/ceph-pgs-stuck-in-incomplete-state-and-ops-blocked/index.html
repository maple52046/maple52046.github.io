<!DOCTYPE html>
<html><head lang="en">
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Ceph pgs stuck in &#39;incomplete&#39; state ,ops blocked - 世界的盡頭</title><meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="Ceph OSD 又再次發生 disk failure，結果在手動修復硬碟時操作不當，整個 disk partition table 都消失了。即使把備份的 disk patition table 寫回去之後，依然無法解決問題。" />
	<meta property="og:image" content=""/>
	<meta property="og:title" content="Ceph pgs stuck in &#39;incomplete&#39; state ,ops blocked" />
<meta property="og:description" content="Ceph OSD 又再次發生 disk failure，結果在手動修復硬碟時操作不當，整個 disk partition table 都消失了。即使把備份的 disk patition table 寫回去之後，依然無法解決問題。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://maple52046.github.io/posts/ceph-pgs-stuck-in-incomplete-state-and-ops-blocked/" /><meta property="og:image" content="https://maple52046.github.io/site-thumbnail.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2015-02-11T17:46:53+00:00" />
<meta property="article:modified_time" content="2015-02-11T17:46:53+00:00" />

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://maple52046.github.io/site-thumbnail.png" /><meta name="twitter:title" content="Ceph pgs stuck in &#39;incomplete&#39; state ,ops blocked"/>
<meta name="twitter:description" content="Ceph OSD 又再次發生 disk failure，結果在手動修復硬碟時操作不當，整個 disk partition table 都消失了。即使把備份的 disk patition table 寫回去之後，依然無法解決問題。"/>

	
        <link href="https://maple52046.github.io/css/fonts.2c2227b81b1970a03e760aa2e6121cd01f87c88586803cbb282aa224720a765f.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="https://maple52046.github.io/css/main.ac08a4c9714baa859217f92f051deb58df2938ec352b506df655005dcaf98cc0.css" />

	
	

	
	
	
	
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="https://maple52046.github.io">世界的盡頭</a>
	</div>
	<nav>
		
		
	</nav>
</header>

<main>
	<article>
		<div class="title">
			<h1 class="title">Ceph pgs stuck in &#39;incomplete&#39; state ,ops blocked</h1>
			<div class="meta">Posted on Feb 11, 2015</div>
		</div>
		

		<section class="body">
			<p>Ceph OSD 又再次發生 <a href="http://worldend.logdown.com/posts/251761-ceph-osd-a-copy-of-the-executable-or-objdump-rds-executable-is-needed-to-interpret-this">disk failure</a>，結果在手動修復硬碟時操作不當，整個 disk partition table 都消失了。即使把備份的 disk patition table 寫回去之後，依然無法解決問題。</p>
<p>無奈之下，硬是將 Ceph cluster 開啟 (少一個 OSD)。
然後執行 <code>ceph health detail</code> 得到以下狀態:</p>
<pre tabindex="0"><code>pg 0.1f is stuck inactive since forever, current state incomplete, last acting [3]
pg 0.1f is stuck unclean since forever, current state incomplete, last acting [3]
pg 0.1f is incomplete, acting [3]
32 ops are blocked &gt; 32.768 sec on osd.3
32 ops are blocked &gt; 32.768 sec on osd.3
1 osds have slow requests
</code></pre><p>按照官網的<a href="http://docs.ceph.com/docs/master/rados/troubleshooting/troubleshooting-pg/#failures-osd-peering">教學</a>，先執行 <code>ceph pg 01.f query</code>，看到 pg 的資訊如下(節錄):</p>
<pre tabindex="0"><code>{ &#34;state&#34;: &#34;incomplete&#34;,
  ...
  &#34;recovery_state&#34;: [
       { &#34;name&#34;: &#34;Started\/Primary\/Peering&#34;,
         &#34;enter_time&#34;: &#34;2012-03-06 14:40:16.169659&#34;,
         &#34;probing_osds&#34;: [
               0,
               1,
               2,
               3],
         &#34;blocked&#34;: &#34;&#34;,
         &#34;down_osds_we_would_probe&#34;: [],
         &#34;peering_blocked_by&#34;: []
}
</code></pre><p>與官網不同的是，這個 pg 並沒有顯示 unfound object，所以執行 <code>ceph pg 0.1f mark_unfound_lost revert</code> 只會出現 <strong>pg has no unfound objects</strong></p>
<p>上網 google 了一下類似問題:</p>
<ul>
<li><a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2013-May/021095.html">[ceph-users] PG down &amp; incomplete</a></li>
<li><a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2014-August/042096.html">[ceph-users] HEALTH_WARN 4 pgs incomplete; 4 pgs stuck inactive; 4 pgs stuck unclean</a></li>
<li><a href="http://www.spinics.net/lists/ceph-users/msg12588.html">pgs stuck in &lsquo;incomplete&rsquo; state, blocked ops,	query command hangs</a></li>
<li><a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2013-November/035826.html">[ceph-users] Constant slow / blocked requests with otherwise healthy cluster</a></li>
<li><a href="http://lists.ceph.com/pipermail/ceph-users-ceph.com/2014-August/042225.html">[ceph-users] HEALTH_WARN 4 pgs incomplete; 4 pgs stuck inactive; 4 pgs stuck unclean</a></li>
</ul>
<p>Google 到的解法大多都是:</p>
<ol>
<li><code>ceph pg 0.1f mark_unfound_lost revert</code></li>
<li><code>ceph pg force_create_pg 0.1f</code></li>
<li>Shutdown Ceph OSD 3</li>
<li><code>ceph osd lost 4 --yes-i-really-mean-it</code></li>
</ol>
<p>但是很遺憾，怎麼做就是沒有任何效果。</p>
<p>如果執行 <code>ceph pg scrub 0.1f</code> 會得到 <strong>instructing pg 0.1f on osd.3 to scrub</strong>，然後就沒下文了。而 <code>deep-scrub</code> 與 <code>repair</code> 也是一樣的狀況。</p>
<p>正當要準備放棄時，忽然靈機一動，調整了一下指令的順序</p>
<h2 id="solution">Solution</h2>
<p>根據 <code>ceph pg 01.f query</code> 得到的結果中得知，pg 0.1f 是存在於 0,1,2,3 這四個 OSD 上:</p>
<pre tabindex="0"><code>recovery_state&#34;: [
       { &#34;name&#34;: &#34;Started\/Primary\/Peering&#34;,
         &#34;enter_time&#34;: &#34;2012-03-06 14:40:16.169659&#34;,
         &#34;probing_osds&#34;: [
               0,
               1,
               2,
               3],
        }
]
</code></pre><p>因此<strong>第一步就是關閉這四個 OSD</strong></p>
<pre tabindex="0"><code>ssh node01 &#34;stop ceph-osd id=0&#34;
ssh node01 &#34;stop ceph-osd id=1&#34;
ssh node02 &#34;stop ceph-osd id=2&#34;
ssh node02 &#34;stop ceph-osd id=3&#34;
</code></pre><p><strong>第二步直接執行 <code>ceph osd lost</code></strong>，一樣也是四個 OSD 都要做:</p>
<pre tabindex="0"><code>ceph osd lost 0 --yes-i-really-mean-it
ceph osd lost 1 --yes-i-really-mean-it
ceph osd lost 2 --yes-i-really-mean-it
ceph osd lost 3 --yes-i-really-mean-it
</code></pre><p>這時候稍微等一段時間(大概5分鐘)，再次執行 <code>ceph health detail</code> 後，發現:</p>
<pre tabindex="0"><code>pg 0.1f is stuck inactive since forever, current state incomplete, last acting []
</code></pre><p>差別在於原本是 <strong>last acting[3]</strong>，代表最後一次是在 OSD 3 上面動作；而現在 pg 0.1f 並沒有在任何一個 OSD 上有動作。</p>
<blockquote>
<p><strong>PS: 此狀態是憑印象寫的，不是非常確定。但是<code>ceph osd lost</code>勢必一定要執行</strong></p>
</blockquote>
<p><strong>第三步就是執行 <code>ceph pg force_create_pg 0.1f</code></strong></p>
<p>然後，神奇的事情來了，過沒幾分鐘後再次執行 <code>ceph health detail</code>，就沒有再看到任何 pg 0.1f 的錯誤訊息</p>
<p><strong>第四步啟動原先四個 OSD</strong></p>
<pre tabindex="0"><code>ssh node01 &#34;start ceph-osd id=0&#34;
ssh node01 &#34;start ceph-osd id=1&#34;
ssh node02 &#34;start ceph-osd id=2&#34;
ssh node02 &#34;start ceph-osd id=3&#34;
</code></pre><p>接下來只需要讓 Ceph 同步一段時間，再次執行 <code>ceph health detail</code>，就可以得到 <strong>HEALTH_OK</strong></p>
<p>收工!!!~</p>
<hr>
<p>利用以上的步驟，雖然終於讓 Ceph 回復到正常狀態，但是與 pg 0.1f 有關的檔案幾乎都是損毀的狀態。因為我是 OpenStack  使用 Ceph，最直觀的影響就是很多 image、instance 無法正常開機。然而本次錯誤狀況其實是可以避免的，原因在於之前將 replication 設為 1。因此一個 OSD 掰掰了，上面的資料變得無法救援，也算是自作自受吧 :&rsquo;(</p>
<hr>
<h2 id="後紀">後紀</h2>
<p>經過這將近半年來各種狀況的考驗，目前對於 Ceph 有一些心得:</p>
<ol>
<li>
<p>OSD 不要架設在 LVM 上。在網路看到很多文章都說是不要安裝在 raid 上，因為 Ceph 已經有自己的 fault torolence。但是根據目前的經驗來看，最好連 LVM 也不要，直接使用一整顆硬碟才是最好的方案。</p>
</li>
<li>
<p>Data replication 最好不要設成 1。否則，天有不測風雲&hellip;。即使要儲存的資料不是這麼重要，但是為了讓 Ceph 能正常運作，replication 建議保留原本的預設值(default is 2)。</p>
</li>
<li>
<p>Ceph cluster 最好要區分 public network 與 cluster network。雖然 cluster network 只有 OSDs 會用到，而且使用率很低。但是在 production 環境上，為了不影響其他 service (例如 OpenStack)，最好將其獨立出來。</p>
</li>
<li>
<p>Disk partition 最好也要做個備份，還有 Ceph 本身的檔案 (/var/lib/ceph/*)</p>
</li>
</ol>
<p>另外，網路上有不少討論 xfs 與 ext4 到底哪個比較適合 Ceph。XFS 似乎在多線程同時讀寫上比 ext4 好，因此才會有 XFS 比 ext4 更適合 Ceph 一說。下次可以試試。</p>
		</section>

		<div class="post-tags">
			
			
			<nav class="nav tags">
				<ul class="tags">
					
					<li><a href="/tags/ceph">ceph</a></li>
					
				</ul>
			</nav>
			
			
		</div>
		</article>
</main>
<footer>
  <div style="display:flex"></div>
  <div class="footer-info">
    2024  <a
      href="https://github.com/athul/archie">Archie Theme</a> | Built with <a href="https://gohugo.io">Hugo</a>
  </div>
</footer>


<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'G-GC1G5TJVGY', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

</div>
    </body>
</html>
